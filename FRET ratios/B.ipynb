{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:46:14.029107Z",
     "end_time": "2023-06-13T20:46:14.052316Z"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from scipy import ndimage\n",
    "from skimage import exposure, transform, io\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import PIL\n",
    "import napari\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from skimage.transform import AffineTransform, warp\n",
    "from scipy.ndimage import fourier_shift,convolve\n",
    "from PIL import Image\n",
    "#\n",
    "import skimage\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Import and inspect the image data\n",
    "# Start coding here\n",
    "filepath ='IPQDA_23_ASS_B_data/W47-SGFP2-mScarlet-I-01-1_2channels.tif'\n",
    "image = tif.imread(filepath)\n",
    "\n",
    "# Start coding here\n",
    "donor_channel = image[:, 0]\n",
    "acceptor_channel = image[:, 1]\n",
    "# End coding here\n",
    "\n",
    "#Calclate and plot the z-projections (use mean) of both channels\n",
    "# Start coding here\n",
    "z_project_donor = np.mean(image[:, 0], axis=0)\n",
    "z_project_acceptor = np.mean(image[:, 1], axis=0)\n",
    "# End coding here\n",
    "\n",
    "# Plot z-projections\n",
    "#plt.imshow(z_project_donor)\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(z_project_acceptor)\n",
    "#plt.show()\n",
    "# Plot the z-projections\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(z_project_donor, cmap='gray')\n",
    "plt.title('Z-Projection (Donor Channel)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(z_project_acceptor, cmap='gray')\n",
    "plt.title('Z-Projection (Acceptor Channel)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:46:16.588213Z",
     "end_time": "2023-06-13T20:46:16.859028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "mean_bg=float(250.49)\n",
    "std_bg=float(129.47)\n",
    "threshold = mean_bg - std_bg\n",
    "background_mask = z_project_donor < threshold\n",
    "\n",
    "z_project_donor[background_mask] = 0\n",
    "z_project_acceptor[background_mask]=0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:46:17.293349Z",
     "end_time": "2023-06-13T20:46:17.319345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "mean_donor=[]\n",
    "mean_acceptor=[]\n",
    "stddev_donor=[]\n",
    "stddev_acceptor=[]\n",
    "#z_project_donor = np.mean(image[:, 0], axis=0)\n",
    "\n",
    "\n",
    "for t in range(len(donor_channel)):\n",
    "    mean_d = np.mean(donor_channel[t])\n",
    "    stddev_d = np.std(donor_channel[t])\n",
    "    mean_a = np.mean(acceptor_channel[t])\n",
    "    stddev_a = np.std(acceptor_channel[t])\n",
    "    mean_donor.append(mean_d)\n",
    "    mean_acceptor.append(mean_a)\n",
    "    stddev_donor.append(stddev_d)\n",
    "    stddev_acceptor.append(stddev_a)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:46:18.059688Z",
     "end_time": "2023-06-13T20:46:18.157240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x20ac92762f0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting\n",
    "plt.plot(mean_donor,label='donor')\n",
    "plt.plot(mean_acceptor,label='acceptor')\n",
    "# Set the labels\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('intensity')\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "#plt.show()#####·········································\n",
    "plt.savefig('IPQDA_B_mean_time.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(stddev_donor,label='donor')\n",
    "plt.plot(stddev_acceptor,label='acceptor')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('intensity')\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:46:18.671324Z",
     "end_time": "2023-06-13T20:46:18.912744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Image processing steps\n",
    "#Initializing parameters\n",
    "# Define a smoothing kernel\n",
    "ks = (3,3) # kernel size should be a tuple\n",
    "kernel = np.ones(ks) / np.prod(ks) # create box filter kernel\n",
    "\n",
    "# Initialize output array\n",
    "corrected_frames = np.zeros_like(image,dtype=np.float64)\n",
    "\n",
    "#Preparing the image data\n",
    "# Convert pixel type to float\n",
    "image = image.astype(np.float64)\n",
    "\n",
    "# Channels extraction\n",
    "donor_channel = image[:,0,:,:]\n",
    "acceptor_channel = image[:,1,:,:]\n",
    "#Now they begin - image processing\n",
    "#image[time,donor/acceptor, X, Y]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:40:49.212287Z",
     "end_time": "2023-06-13T20:40:49.285515Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 70\n",
      "1 of 70\n",
      "2 of 70\n",
      "3 of 70\n",
      "4 of 70\n",
      "5 of 70\n",
      "6 of 70\n",
      "7 of 70\n",
      "8 of 70\n",
      "9 of 70\n",
      "10 of 70\n",
      "11 of 70\n",
      "12 of 70\n",
      "13 of 70\n",
      "14 of 70\n",
      "15 of 70\n",
      "16 of 70\n",
      "17 of 70\n",
      "18 of 70\n",
      "19 of 70\n",
      "20 of 70\n",
      "21 of 70\n",
      "22 of 70\n",
      "23 of 70\n",
      "24 of 70\n",
      "25 of 70\n",
      "26 of 70\n",
      "27 of 70\n",
      "28 of 70\n",
      "29 of 70\n",
      "30 of 70\n",
      "31 of 70\n",
      "32 of 70\n",
      "33 of 70\n",
      "34 of 70\n",
      "35 of 70\n",
      "36 of 70\n",
      "37 of 70\n",
      "38 of 70\n",
      "39 of 70\n",
      "40 of 70\n",
      "41 of 70\n",
      "42 of 70\n",
      "43 of 70\n",
      "44 of 70\n",
      "45 of 70\n",
      "46 of 70\n",
      "47 of 70\n",
      "48 of 70\n",
      "49 of 70\n",
      "50 of 70\n",
      "51 of 70\n",
      "52 of 70\n",
      "53 of 70\n",
      "54 of 70\n",
      "55 of 70\n",
      "56 of 70\n",
      "57 of 70\n",
      "58 of 70\n",
      "59 of 70\n",
      "60 of 70\n",
      "61 of 70\n",
      "62 of 70\n",
      "63 of 70\n",
      "64 of 70\n",
      "65 of 70\n",
      "66 of 70\n",
      "67 of 70\n",
      "68 of 70\n",
      "69 of 70\n"
     ]
    }
   ],
   "source": [
    "for t in range(image.shape[0]):\n",
    "\n",
    "    #######################################\n",
    "    ##Background substraction\n",
    "    #Start coding here\n",
    "    #z_project_donor[background_mask] = 0\n",
    "    #projections [X,Y]\n",
    "    #xqxq=donor_channel[t, :, :] # shape [X,Y]\n",
    "    #background_mask [X, Y]\n",
    "    donor_channel[t, :, :][background_mask] = 0\n",
    "    acceptor_channel[t, :, :][background_mask] = 0\n",
    "\n",
    "    #######################################\n",
    "    ##Image registration\n",
    "    #Calculate the shift between the two images\n",
    "    shift, error, diffphase = phase_cross_correlation(donor_channel[t, :, :],acceptor_channel[t, :, :])\n",
    "\n",
    "    #Create an affine transform object with the shift\n",
    "    tform = AffineTransform(translation=(shift[0],-shift[1]))\n",
    "\n",
    "    #Apply the transformation to the image\n",
    "    corrected_image = warp(acceptor_channel[t, :, :], tform.inverse)\n",
    "\n",
    "    # Replace the original channel with the corrected channel\n",
    "    acceptor_channel[t, :, :] = corrected_image\n",
    "\n",
    "    #######################################\n",
    "    ##Image processing steps to reduce noise\n",
    "    ##Smoothing (hint: use the created kernel)\n",
    "    donor_channel[t, :, :] = convolve(donor_channel[t, :, :], kernel)\n",
    "    acceptor_channel[t, :, :] = convolve(acceptor_channel[t, :, :], kernel)\n",
    "\n",
    "    #Thresholding so that pixels with low signal are assigned with np.nan.\n",
    "    #Use the background mean and standard deviation intensity in this step to form a threshold value\n",
    "\n",
    "    #Well done. Let's keep the corrected frames\n",
    "    corrected_frames[t, 1, :, :] = acceptor_channel[t, :, :]\n",
    "    corrected_frames[t, 0, :, :] = donor_channel[t, :, :]\n",
    "    print(f'{t} of {image.shape[0]}')\n",
    "\n",
    "    # End coding here"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:40:50.279180Z",
     "end_time": "2023-06-13T20:40:52.035261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x20ac92753f0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting\n",
    "plt.imshow(corrected_frames[12, 0,:,:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-13T20:40:53.305346Z",
     "end_time": "2023-06-13T20:40:53.349168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate FRET ratios. R = Acceptor/Donor\n",
    "# Start coding here\n",
    "print(corrected_frames.shape)\n",
    "ratio = corrected_frames[:,1,:,:]/corrected_frames[:,0,:,:]\n",
    "#print(ratio)\n",
    "\"\"\"\n",
    "ratio=[]\n",
    "for t in range(image.shape[0]):\n",
    "    r=corrected_frames[t, 1, :, :] / corrected_frames[t, 0, :, :]\n",
    "    #plt.imshow(r)\n",
    "    #plt.show()\n",
    "    ratio.append(r)\n",
    "ratio = np.stack(ratio)\n",
    "# End coding here\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "frames = []\n",
    "for i in range(ratio.shape[0]):\n",
    "    # Create a PIL Image object from the current frame\n",
    "    frame = Image.fromarray(ratio[i])\n",
    "    frames.append(frame)\n",
    "\n",
    "frames[0].save(\"ratio.gif\", format=\"GIF\", append_images=frames[1:], save_all=True, duration=200, loop=0)\n",
    "\"\"\"\n",
    "#Plot a layer\n",
    "plt.imshow(ratio[12,:,:])\n",
    "#plt.show() #####·········································\n",
    "# Export the FRET ratios images as an animated gif\n",
    "# Start coding here\n",
    "imageio.mimsave('fret_ratios.gif', ratio, format='GIF',duration=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
